{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48a3914d-38fe-4ff6-b40d-b86f6c9f0447",
   "metadata": {},
   "source": [
    "### Birkhoff’s Decomposition Revisited: Sparse Scheduling for High-Speed Circuit Switches\n",
    "https://www.semanticscholar.org/paper/Birkhoff's-Decomposition-Revisited%3A-Sparse-for-Valls-Iosifidis/e9c0e0d1bf7c220e9f471b6fe28bce2c45929c3c\n",
    "\n",
    "#### Problem definition:\n",
    "For a given $n \\times n$ doubly stochastic matrix $X^{\\star}$ and an $\\epsilon \\leq 0$, our goal is to find a small collection of permutation matrices $P_{1}, P_{2}, \\ldots, P_{k}$, and weights $\\theta_{1}, \\theta_{2}, \\ldots, \\theta_{k}$ with $\\sum_{i=1}^{k}\\theta_{i} \\leq 1$ such that $\\lVert X^{\\star} - \\sum_{i=1}^{k}\\theta_{i}P_{i} \\rVert_{F} \\leq \\epsilon$.\n",
    "\n",
    "#### Definitions\n",
    "1. When applied to vector or matrix, $+, -, \\cdot$ are all elementwise operations and we write $x < (\\leq, >, \\geq ) y$ when all elements of $x$ are $< (\\leq, >, \\geq)$ of all elements of $y$.\n",
    "1. Frobenius norm: $\\lVert X \\rVert_{F} = \\sqrt{\\sum_{i, j}\\vert X(i, j) \\vert^2}$, which is the same as the l2 norm of a vector: $\\lVert x \\rVert_{2} = \\sqrt{\\sum_{i}\\vert x(i) \\vert^2}$\n",
    "1. Convex hull $\\mathrm{conv}(A)$: The convex hull of set A ($\\mathrm{conv}(A)$) is the smallest convex set that contains $A$.\n",
    "1. Birkhoff polytope $\\mathcal{B}$: the convex set that contains all doubly stochastic matrices of size $n \\times n$. \n",
    "1. Permutation matrices $\\mathcal{P}$: the extreme points of the Birkhoff polytope.\n",
    "1. Linear program $\\mathrm{LP}(c, \\mathcal{X})$: minimize $c^{T}x$, subject to $x \\in \\mathcal{X}$. We assume that the solution returned is always an extreme point ($x \\in \\mathcal{P}$ if $\\mathcal{X} = \\mathcal{B}$). \n",
    "1. Birkhoff step: $\\mathrm{STEP}(X^{\\star}, X_{k-1}, P_{k}) = \\min_{a,b}\\{(X^{\\star}(a, b) - X_{k-1}(a,b) - 1)P_{k}(a,b) + 1\\}$. It computes the step size (weight) by taking the minimum non-zero entry of the difference matrix (masked by the permutation matrix $P_{k}$) between $X^{\\star}$ and $X$.\n",
    "\n",
    "#### Algorithms (All matrices are represented using vectors by stacking the matrix columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c386e0-43b2-47d8-a70b-bd462a1ca7e5",
   "metadata": {},
   "source": [
    "##### General Birkoff algorithm (Algorithm 1, 2 and 3)\n",
    "\n",
    "> 1. $x_{0} = 0, k = 0$\n",
    "> 1. **while** $\\lVert x^{\\star} - x_{k-1} \\rVert_{2} > \\epsilon$ and $k \\leq k_{max}$ **do**\n",
    "> 1. &ensp; $\\alpha \\gets (1 - \\sum_{i=1}^{k-1}\\theta_{i}) \\mathbin{/} n^2$ // **(Why this value)**\n",
    "> 1. &ensp; $p_{k} \\gets p \\in \\mathcal{I}_{k}(\\alpha)$ &ensp; // Get next permutation matrix \n",
    "> 1. &ensp; $\\theta_{k} \\gets$ $\\mathrm{STEP}(x^{\\star}, x_{k-1}, p_k)$ &ensp; // Get next weight based on the new permutation matrix\n",
    "> 1. &ensp; $x_{k} \\gets x_{k-1} + \\theta_{k}p_{k}$\n",
    "> 1. &ensp; $k \\gets k + 1$\n",
    "> 1. **end while**\n",
    "> 1. **return** $(p_{1}, \\ldots, p_{k-1})$, $(\\theta_{1}, \\ldots, \\theta_{k-1})$\n",
    "\n",
    "##### Notes\n",
    "1. $n$ is the size of $X^{\\star}$ and thus $d=n^2$ is the number of elements in $X^{\\star}$.\n",
    "1. $\\mathcal{I}_{k}(\\alpha) =\\{P\\in\\mathcal{P} \\mid X_{k-1}(a,b) + \\alpha P(a,b) \\leq X^{\\star}(a,b) \\}$.\n",
    "1. Since the Birkhoff step functions only takes the minimum non-zero difference as the next step, $x_{k} \\leq x^{\\star}$ all the time. \n",
    "    1. Birkhoff’s algorithm can be seen as constructing a path from the origin ($x_{0} = 0$) to $x^{\\star}$ while always remaining in a dotted box, where $x_{0}$ and $x^{\\star}$ are two diagonal vertices of the box ($x_{k} \\leq x^{\\star}$).\n",
    "1. General Birkoff algorithm doesn't specify which specific permutation to select from $\\mathcal{I}_{k}(\\alpha)$.\n",
    "1. A specific way to select permutation matrix is by solving a linear program. In this way Lines 3 and 4 are replaced with the codes below (Algorithm 4). \n",
    "> $p_k \\gets \\mathrm{LP}(-\\lceil x^{\\star} - x_{k-1} \\rceil, \\mathcal{B})$.\n",
    "    1. Since $x^{\\star} - x_{k-1} \\in [0, 1]$, its ceiling ($\\lceil x^{\\star} - x_{k-1} \\rceil$) makes all nonzero elements to be 1. Thus, the solution of $LP$ will treat all nonzero elements equally. **(Why need equally)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab690479-d612-4439-8220-07e6ff140e37",
   "metadata": {},
   "source": [
    "##### Frank-Wolfe (FW) algorithm (Algorithm 4)\n",
    "\n",
    "> 1. $x_{0} \\in \\mathcal{P}, k = 0$\n",
    "> 1. **while** $\\lVert x^{\\star} - x_{k-1} \\rVert_{2} > \\epsilon$ and $k \\leq k_{max}$ **do**\n",
    "> 1. &ensp; $p_k \\gets \\mathrm{LP}(-(x^{\\star} - x_{k-1}), \\mathcal{B})$ // Get the next extreme point \n",
    "> 1. &ensp; $\\theta_{k} \\gets (x^{\\star} - x_{k-1})^{T}(p_{k} - x_{k-1}) \\mathbin{/} \\lVert p_{k} - x_{k-1} \\rVert_{2}^{2}$ // Calculate the step size\n",
    "> 1. &ensp; $x_{k} \\gets x_{k-1} + \\theta_{k}(p_{k} - x_{k-1})$ // Update the approximate x\n",
    "> 1. &ensp; $k \\gets k + 1$\n",
    "> 1. **end while**\n",
    "> 1. **return** $(p_{1}, \\ldots, p_{k-1})$, $(\\theta_{1}, \\ldots, \\theta_{k-1})$\n",
    "\n",
    "##### Notes\n",
    "1. The assumption of the FW algorithm is that there always exists an extreme point in the Birkhoff polytope (permutation matrix $p_{k}$) that is a direction ($p_{k} - x_{k-1}$) in which it is possible to improve the objective function.\n",
    "1. Since each extreme point of the Birkhoff polytope is an permutation matrix and thus the each step size can be considered as the weight of the permutation matrix, FW algorithm can be used to solve Birkhoff problem. \n",
    "1. The paper selects the objective function to be $f(x) = \\frac{1}{2} \\lVert x - x^{\\star} \\rVert_{2}^{2}$, which measures the square of the l2 norm of the difference between the current matrix $x_{k}$ and the objective matrix $x^{\\star}$. $\\nabla f(x) = -(x^{\\star} - x_{k-1})$\n",
    "1. The solving of $\\mathrm{LP}$ at line 3 is esentially trying to find the extreme point $p_{k}$ by solving $\\underset{u \\in \\mathcal{P}}{\\mathrm{argmin}}\\nabla f(x_{k-1})^{T}u$.\n",
    "1. Difference with the Birkhoff algorithm: \n",
    "    1. FW uses a random extreme point instead of 0 as the starting point because it wants all solution to be extreme points.\n",
    "    1. FW does not require that $x_{k} \\leq x^{\\star}$.\n",
    "1. Fully Corrective Frank-Wolfe (FCFW). \n",
    "    1. This variant of Frank-Wolfe differers from the classic FW algorithm because it provides the best approximation with the number of extreme points selected up to iteration k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16284203-b627-4275-8225-fb6a50fc74df",
   "metadata": {},
   "source": [
    "##### Birkhoff+ algorithm \n",
    "\n",
    "> 1. $x_{0} = 0, k = 0$\n",
    "> 1. **while** $\\lVert x^{\\star} - x_{k-1} \\rVert_{2} > \\epsilon$ and $k \\leq k_{max}$ **do**\n",
    "> 1. &ensp; $\\alpha \\gets (1 - \\sum_{i=1}^{k-1} \\theta_i) \\mathbin{/} n^2$\n",
    "> 1. &ensp; $p_{i} \\gets \\mathrm{LP}(\\nabla f_{\\beta}(x_{k-1}), \\mathrm{conv}(\\mathcal{I}_{k}(\\alpha)))$\n",
    "> 1. &ensp; $\\theta_{k} \\gets$ $\\mathrm{STEP}(x^{\\star}, x_{k-1}, p_k)$\n",
    "> 1. &ensp; $x_{k} \\gets x_{k-1} + \\theta_{k}p_{k}$\n",
    "> 1. &ensp; $k \\gets k + 1$\n",
    "> 1. **end while**\n",
    "> 1. **return** $(p_{1}, \\ldots, p_{k-1})$, $(\\theta_{1}, \\ldots, \\theta_{k-1})$\n",
    "\n",
    "##### Notes:\n",
    "1. Birkhoff+ combines Birkhoff algorithm and FW algorithm. This approach wants to use the path or permutations that Frank-Wolfe would select while remaining in the box that characterizes the Birkhoff’s approach.\n",
    "1. The only real difference between Birkhoff+ and Birkhoff is the way to compute $p_{k}$ (line 4). \n",
    "    1. $f_{\\beta}(x) = f(x) - \\beta \\sum_{j=1}^{d} \\log(x^{\\star}(j) - x(j) + \\frac{\\epsilon}{d})$\n",
    "    1. The main objective function $f(x)$ is the same as used in FW algorithm, while the remaining part $- \\beta \\sum_{j=1}^{d} \\log(x^{\\star}(j) - x(j) + \\frac{\\epsilon}{d})$ is a penalty term (barrier) that restricts the point to remain in the Birkhoff box. **(why this equation can achieve it)**\n",
    "    1. $\\beta$ is a hyper-parameter that balances the objective function and the barrier. In the code, tt is tuned smaller and smaller as the $x_{k}$ is getting closed to $x^{\\star}$. \n",
    "    1. $\\frac{\\epsilon}{d}$ is used to avoid $\\log \\to \\infty$ \n",
    "1. $\\mathrm{LP}(\\nabla f_{\\beta}(x_{k-1}), \\mathrm{conv}(\\mathcal{I}_{k}(\\alpha))) = \\mathrm{LP}(\\nabla f_{\\beta}(x_{k-1}) + b_{k}, \\mathcal{B})$, where $b_{k} = \\frac{\\epsilon}{d} \\cdot \\mathrm{sign}(x^{\\star} - x_{k-1} \\leq \\alpha)$ is a penalty vector to force the solver to do not select the components of vector $(x^{\\star} - x_{k})$ smaller than $\\alpha$. **(why this equation can achieve it)**\n",
    "    \n",
    "##### Birkhoff+ (max_rep) algorithm \n",
    "\n",
    "> 1. $x_{0} = 0, k = 0$\n",
    "> 1. **while** $\\lVert x^{\\star} - x_{k-1} \\rVert_{2} > \\epsilon$ and $k \\leq k_{max}$ **do**\n",
    "> 1. &ensp; $\\alpha \\gets (1 - \\sum_{i=1}^{k-1} \\theta_i) \\mathbin{/} n^2$\n",
    "> 1. &ensp; **for** $i = 1,\\ldots, \\mathrm{max\\_rep}$ **do**\n",
    "> 1. &ensp; &ensp; $p_{i} \\gets \\mathrm{LP}(\\nabla f_{\\beta}(x_{k-1}), \\mathrm{conv}(\\mathcal{I}_{k}(\\alpha)))$\n",
    "> 1. &ensp; &ensp; $\\theta_{i} \\gets \\mathrm{STEP}(x^{\\star}, x_{k-1}, p_{k})$\n",
    "> 1. &ensp; &ensp; **if** $(\\theta_{i} > \\alpha)$ $\\alpha \\gets \\mathrm{STEP}(x^{\\star}, x_{k-1}, p_{k})$\n",
    "> 1. &ensp; &ensp; **else** exit while loop\n",
    "> 1. &ensp; &ensp; $p_{k} \\gets p_{i}$\n",
    "> 1. &ensp; **end for**\n",
    "> 1. &ensp; $\\theta_{k} \\gets$ $\\mathrm{STEP}(x^{\\star}, x_{k-1}, p_k)$\n",
    "> 1. &ensp; $x_{k} \\gets x_{k-1} + \\theta_{k}p_{k}$\n",
    "> 1. &ensp; $k \\gets k + 1$\n",
    "> 1. **end while**\n",
    "> 1. **return** $(p_{1}, \\ldots, p_{k-1})$, $(\\theta_{1}, \\ldots, \\theta_{k-1})$\n",
    "\n",
    "1. Instead of using a constant $\\alpha$, Birkhoff+ (max_rep) searches the largest the $\\alpha$ in each iteration by alternatively updating $\\alpha$  and $p_{k}$ until $\\alpha$ cannot be updated larger or $\\mathrm{max\\_rep}$ iterations is reached. **(Why want larger $\\alpha$ value)**\n",
    "    1. $\\alpha$ is set to be the largest step size (weight from $\\mathrm{STEP}$ function) found so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e40950e5-3383-48ca-a12f-2ade961e9317",
   "metadata": {},
   "outputs": [],
   "source": [
    "using JuMP\n",
    "using Clp\n",
    "using Random\n",
    "using SparseArrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d56604b6-f9ba-4bf1-a48b-f96fe4698982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "birkhoffPolytope"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# functionsBD.jl\n",
    "\n",
    "struct polytope\n",
    "    A;\n",
    "    b;\n",
    "    l;\n",
    "    u;\n",
    "    model;\n",
    "    x;\n",
    "end\n",
    "\n",
    "@doc raw\"\"\"\n",
    "Solve a linear programing problem\n",
    "\"\"\"\n",
    "function LP(c, P)\n",
    "    @objective(P.model, Min, c'* P.x)\n",
    "    optimize!(P.model)\n",
    "    return value.(P.x)\n",
    "end\n",
    "\n",
    "@doc raw\"\"\"\n",
    "Get a random stochastic matrix\n",
    "\"\"\"\n",
    "function randomDoublyStochasticMatrix(n; num_perm=n^2)\n",
    "    M = zeros(n, n);\n",
    "    α = rand(num_perm)\n",
    "\n",
    "    α = α / sum(α);\n",
    "\n",
    "    for i = 1:num_perm\n",
    "        perm = randperm(n);\n",
    "        for j = 1:n\n",
    "            M[perm[j], j] += α[i];\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return M;\n",
    "end\n",
    "\n",
    "\n",
    "@doc raw\"\"\"\n",
    "Create Birkhoff polytope ``\\mathcal{B}`` (Section V-A), which contains all possible doublely stochastic matrices.\n",
    "\n",
    "Since the paper assumes that the solutions by solving linear programs over are Birkhoff polytope extreme points, \n",
    "the solutions are permutation matrices (which are also doublely stochastic). \n",
    "\"\"\"\n",
    "function birkhoffPolytope(n)\n",
    "    # x is a doublely stochastic matrix that is represented by a vector (flattened).\n",
    "    # Use a constant matrix A(M') and a constant vector b to specify that x is doublely stochastic.\n",
    "    \n",
    "    M = zeros(n*n, 2*n);\n",
    "    # Specify the sum of each row of x equals to 1\n",
    "    for i = 1:n\n",
    "        M[(i-1)*n*n + (i-1)*n + 1 : (i-1)*n*n + (i-1)*n + n] = ones(n,1);\n",
    "    end\n",
    "    # Specify the sum of each col of x equals to 1\n",
    "    for i = 1:n\n",
    "        for j=1:n\n",
    "            M[n*n*n + (i-1)*n*n + (j-1)*n + i] = 1;\n",
    "        end\n",
    "    end\n",
    "\n",
    "    A = sparse(M');\n",
    "    b = ones(2*n);\n",
    "\n",
    "    model = Model(Clp.Optimizer)\n",
    "    set_silent(model)\n",
    "    @variable(model, 0 <= x[1:n*n] <= 1)\n",
    "    @constraint(model, A * x .== b)\n",
    "\n",
    "    return polytope(A, b, 0, 1, model, x)\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "651974ed-3aba-4826-bb42-afdd8f7a0c79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "getBirkhoffStepSize"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stepsizes.jl\n",
    "\n",
    "@doc raw\"\"\"\n",
    "Get the step size (weight) by taking the minimum non-zero entry of the difference matrix \n",
    "(masked by the permutation matrix y) between x_star and x.\n",
    "\"\"\"\n",
    "function getBirkhoffStepSize(x_star, x, y)\n",
    "    return minimum((x_star - x).*y - (y.-1));\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecaface7-4b24-4934-a930-d52ea7da49ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "getEPBplus (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extremepoints.jl\n",
    "\n",
    "@doc raw\"\"\"\n",
    "Birkhoff+ (max_rep) Psudocode line 4-10\n",
    "\"\"\"\n",
    "function getEPBplus(x_star, x, B, max_rep, ε)\n",
    "    n = sqrt(size(x_star, 1))\n",
    "    d = size(x_star, 1);\n",
    "    i = 1;\n",
    "    y = 0;\n",
    "    α = 0;\n",
    "\n",
    "    while(i <= max_rep)\n",
    "        # Calculate \\beta for this iteration.\n",
    "        # \\beta should become smaller and smaller.\n",
    "        z = Int16.(x_star - x .> ε)\n",
    "        s = getBirkhoffStepSize(x_star, x, z)\n",
    "        beta = (s + ε/d)*0.5\n",
    "\n",
    "        # c is the gradient of the objective function with barrier.\n",
    "        # b is an iterm added to make I_k(\\alpha) to be B (Birkhoff polytope).\n",
    "        # See the paragraph in section VI.B after Corollary 2 for b.\n",
    "        c = -ones(d) + beta ./ (x_star - x .+ ε/d)\n",
    "        b = (n/ε).*Int16.(x_star - x .<= α)\n",
    "        y_iter = LP(c + b, B);\n",
    "        \n",
    "        # If new solution (y_iter) makes objective function larger/worse (c'*y_iter > c'*y_z),\n",
    "        # fall back to the solution from the last iteration (y_z/x).\n",
    "        y_z = x;\n",
    "        if(c'*y_iter > c'*y_z)\n",
    "            y_iter = y_z\n",
    "        end\n",
    "\n",
    "        # \\alpha should be the largest step size found. \n",
    "        # Algorithm terminates when \\alpha doesn't increase\n",
    "        α_iter = getBirkhoffStepSize(x_star, x, y_iter);\n",
    "        if(α < α_iter)\n",
    "            α = α_iter;\n",
    "            y = y_iter;\n",
    "        else\n",
    "            return y;\n",
    "        end\n",
    "        i = i + 1;\n",
    "    end\n",
    "\n",
    "    return y\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cea9cc3-de9a-466d-b5d7-e60a43444fca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "birkdecomp (generic function with 2 methods)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# birkdecomp.jl\n",
    "\n",
    "@doc raw\"\"\"\n",
    "Birkhoff+ (max_rep)\n",
    "\"\"\"\n",
    "function birkdecomp(X, ε=1e-12; max_rep=1)\n",
    "    n = size(X, 1);                                 # get size of Birkhoff polytope\n",
    "    x_star = reshape(X, n*n);                       # reshape doubly stochastic to vector\n",
    "    B = birkhoffPolytope(n);                        # Birkhoff polytope\n",
    "    ε = max(ε, 1e-15);                              # fix the maximum minimum precision\n",
    "    max_iter = (n-1)^2 + 1;\n",
    "\n",
    "    x = zeros(n*n);                                 # initial point\n",
    "\n",
    "    extreme_points = zeros(n*n, max_iter);          # extreme points (permutation) matrix\n",
    "    θ = zeros(max_iter);                            # weights vector\n",
    "    approx = Inf;                                   # approximation error\n",
    "    i = 1;                                          # iteration index\n",
    "\n",
    "    while(approx > ε)\n",
    "        # Get next extreme point \n",
    "        y = getEPBplus(x_star, x, B, max_rep, ε)\n",
    "        # Get next weight (step size)\n",
    "        θi = getBirkhoffStepSize(x_star, x, y)\n",
    "        # Update x_k\n",
    "        x = x + θi*y;\n",
    "        # Store the new weight\n",
    "        θ[i] = θi;\n",
    "\n",
    "        # Update the Frobenius norm\n",
    "        approx = sqrt(sum((abs.(x_star-x)).^2));\n",
    "        \n",
    "        # Store the new extreme point matrix\n",
    "        extreme_points[:,i] = y;\n",
    "        i = i + 1;\n",
    "    end\n",
    "\n",
    "    return extreme_points[:, 1:i-1], θ[1:i-1]\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9a9cbd0-57ee-45f7-9160-bb8c8e4ee9a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×3 Array{Float64,2}:\n",
       " 0.0607488  0.590595   0.348656\n",
       " 0.70177    0.0291194  0.269111\n",
       " 0.237482   0.380286   0.382233"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "9×5 Array{Float64,2}:\n",
       " 0.0  0.0  0.0  1.0  0.0\n",
       " 1.0  1.0  0.0  0.0  0.0\n",
       " 0.0  0.0  1.0  0.0  1.0\n",
       " 1.0  0.0  1.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  1.0\n",
       " 0.0  1.0  0.0  1.0  0.0\n",
       " 0.0  1.0  0.0  0.0  1.0\n",
       " 0.0  0.0  1.0  1.0  0.0\n",
       " 1.0  0.0  0.0  0.0  0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "5-element Array{Float64,1}:\n",
       " 0.38223288955133716\n",
       " 0.31953666864401353\n",
       " 0.20836217653438616\n",
       " 0.06074883235172196\n",
       " 0.029119432918541188"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate a random doubly stochastic matrix (n is the dimension)\n",
    "n = 3;\n",
    "x = randomDoublyStochasticMatrix(n);\n",
    "P, w = birkdecomp(x);\n",
    "\n",
    "display(x)\n",
    "display(P);\n",
    "display(w);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51bbdc23-3532-4a06-ab0b-624298e37158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×3 Array{Float64,2}:\n",
       " 0.0607488  0.590595   0.348656\n",
       " 0.70177    0.0291194  0.269111\n",
       " 0.237482   0.380286   0.382233"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_new = zeros(n, n)\n",
    "for i=1:length(w)\n",
    "    x_new = x_new + w[i] * reshape(P[:, i], n, n) \n",
    "end\n",
    "display(x_new)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.1",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
